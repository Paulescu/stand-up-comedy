{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2424402b",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5541c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local...\n",
      "Environment: \n",
      "SRC_DIR: \t /Users/paulabartabajo/src/online-courses/stand-up-comedy/stand_up_comedy\n",
      "DATA_DIR: \t /Users/paulabartabajo/src/online-courses/stand-up-comedy/data\n",
      "MODELS_DIR: \t /Users/paulabartabajo/src/online-courses/stand-up-comedy/models\n",
      "TENSORBOARD_DIR: \t /Users/paulabartabajo/src/online-courses/stand-up-comedy/tensorboard\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running in Colab')\n",
    "    # pull code from github\n",
    "    !git clone https://github.com/Paulescu/stand-up-comedy.git\n",
    "    !pip install -q -r stand-up-comedy/requirements.txt\n",
    "\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "else:\n",
    "    print('Running in local...')\n",
    "    \n",
    "    SRC_DIR = '/Users/paulabartabajo/src/online-courses/stand-up-comedy/stand_up_comedy'\n",
    "    DATA_DIR = '/Users/paulabartabajo/src/online-courses/stand-up-comedy/data'\n",
    "    MODELS_DIR = '/Users/paulabartabajo/src/online-courses/stand-up-comedy/models'\n",
    "    TENSORBOARD_DIR = '/Users/paulabartabajo/src/online-courses/stand-up-comedy/tensorboard'\n",
    "    \n",
    "print('Environment: ')\n",
    "print('SRC_DIR: \\t', SRC_DIR)\n",
    "print('DATA_DIR: \\t', DATA_DIR)\n",
    "print('MODELS_DIR: \\t', MODELS_DIR)\n",
    "print('TENSORBOARD_DIR: \\t', TENSORBOARD_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173648ad",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f0b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db18e6912989a24f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db18e6912989a24f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $TENSORBOARD_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1dc3e",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12326192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using custom data configuration default-550375832cd40692\n",
      "Reusing dataset csv (/Users/paulabartabajo/.cache/huggingface/datasets/csv/default-550375832cd40692/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
      "Parameter 'function'=<function ComedianDataModule.setup.<locals>.tokenize_function at 0x12e7c8440> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.40ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22ba/s]\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 464.71ex/s]\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 465.52ex/s]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 124 M \n",
      "------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.768   Total estimated model params size (MB)\n",
      "/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Validation sanity check:   0%|                            | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/stand_up_comedy/model.py\", line 220, in <module>\n",
      "    cli_main()\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/stand_up_comedy/model.py\", line 201, in cli_main\n",
      "    trainer.fit(model, data_module)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 499, in fit\n",
      "    self.dispatch()\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 546, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 73, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 114, in start_training\n",
      "    self._results = trainer.run_train()\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 607, in run_train\n",
      "    self.run_sanity_check(self.lightning_module)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 864, in run_sanity_check\n",
      "    _, eval_results = self.run_evaluation(max_batches=self.num_sanity_val_batches)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 726, in run_evaluation\n",
      "    output = self.evaluation_loop.evaluation_step(batch, batch_idx, dataloader_idx)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 166, in evaluation_step\n",
      "    output = self.trainer.accelerator.validation_step(args)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 177, in validation_step\n",
      "    return self.training_type_plugin.validation_step(*args)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 131, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/stand_up_comedy/model.py\", line 52, in validation_step\n",
      "    loss = self.model(**batch).loss\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 917, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 760, in forward\n",
      "    output_attentions=output_attentions,\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 296, in forward\n",
      "    output_attentions=output_attentions,\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 241, in forward\n",
      "    attn_outputs = self._attn(query, key, value, attention_mask, head_mask, output_attentions)\n",
      "  File \"/Users/paulabartabajo/src/online-courses/stand-up-comedy/.venv/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 168, in _attn\n",
      "    w = torch.matmul(q, k)\n",
      "KeyboardInterrupt\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!python $SRC_DIR/model.py \\\n",
    "    --train_file $DATA_DIR/ml/train_small.csv \\\n",
    "    --validation_file $DATA_DIR/ml/test_small.csv \\\n",
    "    --train_batch_size 2 \\\n",
    "    --validation_batch_size 2 \\\n",
    "    --max_seq_length 768 \\\n",
    "    --checkpoint_dir $MODELS_DIR \\\n",
    "    --tensorboard_dir $TENSORBOARD_DIR\n",
    "#     --fast_dev_run 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff1b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
